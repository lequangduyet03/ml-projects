# Machine Learning Projects - Classification, Regression & Time Series

Dá»± Ã¡n Machine Learning vá»›i 5 bÃ i toÃ¡n: PhÃ¢n loáº¡i bá»‡nh tiá»ƒu Ä‘Æ°á»ng, Dá»± Ä‘oÃ¡n Ä‘iá»ƒm sá»‘ há»c sinh, PhÃ¢n loáº¡i cáº¥p Ä‘á»™ nghá» nghiá»‡p, vÃ  2 bÃ i toÃ¡n Time Series dá»± Ä‘oÃ¡n ná»“ng Ä‘á»™ CO2.

## ğŸ“‹ Má»¥c lá»¥c
- [Giá»›i thiá»‡u](#giá»›i-thiá»‡u)
- [Dataset](#dataset)
- [CÃ´ng nghá»‡ sá»­ dá»¥ng](#cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [CÃ¡ch sá»­ dá»¥ng](#cÃ¡ch-sá»­-dá»¥ng)
- [Káº¿t quáº£](#káº¿t-quáº£)
- [Cáº¥u trÃºc thÆ° má»¥c](#cáº¥u-trÃºc-thÆ°-má»¥c)

## ğŸ¯ Giá»›i thiá»‡u

Repository nÃ y chá»©a 5 dá»± Ã¡n Machine Learning:

### 1. Classification - Dá»± Ä‘oÃ¡n bá»‡nh tiá»ƒu Ä‘Æ°á»ng
- **Thuáº­t toÃ¡n**: Random Forest Classifier
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n xem bá»‡nh nhÃ¢n cÃ³ máº¯c bá»‡nh tiá»ƒu Ä‘Æ°á»ng hay khÃ´ng
- **Dataset**: diabetes.csv (768 samples, 8 features)
- **Target**: Outcome (0 = KhÃ´ng bá»‹ tiá»ƒu Ä‘Æ°á»ng, 1 = Bá»‹ tiá»ƒu Ä‘Æ°á»ng)

### 2. Regression - Dá»± Ä‘oÃ¡n Ä‘iá»ƒm toÃ¡n há»c sinh
- **Thuáº­t toÃ¡n**: Random Forest Regressor
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n Ä‘iá»ƒm toÃ¡n cá»§a há»c sinh dá»±a trÃªn cÃ¡c yáº¿u tá»‘ khÃ¡c
- **Dataset**: StudentScore.xls (1000 samples)
- **Target**: Math Score

### 3. Job Classification - PhÃ¢n loáº¡i cáº¥p Ä‘á»™ nghá» nghiá»‡p
- **Thuáº­t toÃ¡n**: Random Forest Classifier vá»›i Feature Selection
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n cáº¥p Ä‘á»™ nghá» nghiá»‡p (career level) tá»« thÃ´ng tin cÃ´ng viá»‡c
- **Dataset**: final_project.ods
- **Target**: career_level (6 classes)
- **Ká»¹ thuáº­t Ä‘áº·c biá»‡t**: 
  - TF-IDF cho text features (title, description)
  - One-Hot Encoding cho categorical features
  - Random Over-sampling Ä‘á»ƒ xá»­ lÃ½ imbalanced data
  - Chi-square feature selection

### 4. Time Series - Dá»± Ä‘oÃ¡n CO2 (Direct Multi-step)
- **Thuáº­t toÃ¡n**: Linear Regression (Multi-output)
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n ná»“ng Ä‘á»™ CO2 cho 3 tuáº§n tiáº¿p theo cÃ¹ng lÃºc
- **Dataset**: co2.csv (Time series data)
- **PhÆ°Æ¡ng phÃ¡p**: Direct Multi-step Forecasting
- **Window size**: 5 tuáº§n
- **Target size**: 3 tuáº§n
- **Äáº·c Ä‘iá»ƒm**: Train 3 models riÃªng biá»‡t cho má»—i bÆ°á»›c dá»± Ä‘oÃ¡n

### 5. Time Series - Dá»± Ä‘oÃ¡n CO2 (Recursive)
- **Thuáº­t toÃ¡n**: Linear Regression
- **Má»¥c tiÃªu**: Dá»± Ä‘oÃ¡n ná»“ng Ä‘á»™ CO2 cho nhiá»u tuáº§n tiáº¿p theo
- **Dataset**: co2.csv (Time series data)
- **PhÆ°Æ¡ng phÃ¡p**: Recursive Forecasting
- **Window size**: 5 tuáº§n
- **Äáº·c Ä‘iá»ƒm**: 
  - Sá»­ dá»¥ng 1 model duy nháº¥t
  - Dá»± Ä‘oÃ¡n tá»«ng bÆ°á»›c, má»—i dá»± Ä‘oÃ¡n Ä‘Æ°á»£c dÃ¹ng lÃ m input cho bÆ°á»›c tiáº¿p theo
  - CÃ³ visualization so sÃ¡nh train/test/prediction

## ğŸ“Š Dataset

### Diabetes Dataset
CÃ¡c features bao gá»“m:
- Pregnancies (Sá»‘ láº§n mang thai)
- Glucose (Ná»“ng Ä‘á»™ Ä‘Æ°á»ng huyáº¿t)
- Blood Pressure (Huyáº¿t Ã¡p)
- Skin Thickness (Äá»™ dÃ y da)
- Insulin (Ná»“ng Ä‘á»™ insulin)
- BMI (Chá»‰ sá»‘ khá»‘i cÆ¡ thá»ƒ)
- Diabetes Pedigree Function
- Age (Tuá»•i)

### Student Score Dataset
CÃ¡c features bao gá»“m:
- Gender (Giá»›i tÃ­nh)
- Race/Ethnicity (Chá»§ng tá»™c)
- Parental Level of Education (TrÃ¬nh Ä‘á»™ há»c váº¥n cá»§a cha máº¹)
- Lunch (Loáº¡i bá»¯a trÆ°a)
- Test Preparation Course (KhÃ³a Ã´n thi)
- Reading Score (Äiá»ƒm Ä‘á»c)
- Writing Score (Äiá»ƒm viáº¿t)

### Job Classification Dataset
CÃ¡c features bao gá»“m:
- **title**: Chá»©c danh cÃ´ng viá»‡c (text)
- **description**: MÃ´ táº£ cÃ´ng viá»‡c (text - unigrams + bigrams)
- **location**: Vá»‹ trÃ­ Ä‘á»‹a lÃ½ (categorical)
- **function**: Chá»©c nÄƒng/phÃ²ng ban (categorical)
- **industry**: NgÃ nh nghá» (categorical)

Target classes (career_level):
- bereichsleiter
- director_business_unit_leader
- manager_team_leader
- managing_director_small_medium_company
- senior_specialist_or_project_manager
- specialist

### CO2 Time Series Dataset
- **time**: Timestamp (datetime)
- **co2**: Ná»“ng Ä‘á»™ CO2 trong khÃ­ quyá»ƒn
- **Äáº·c Ä‘iá»ƒm**: 
  - Time series data vá»›i missing values (Ä‘Ã£ xá»­ lÃ½ báº±ng interpolation)
  - Train/test split theo thá»i gian (80/20)
  - Window-based features (sliding window)

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

- Python 3.8+
- scikit-learn
- pandas
- numpy
- matplotlib (visualization)
- imbalanced-learn (imblearn)
- openpyxl (Ä‘á»c file .ods)

## âš™ï¸ CÃ i Ä‘áº·t

1. Clone repository:
```bash
git clone https://github.com/lequangduyet03/ml-projects
cd ml-projects
```

2. CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t:
```bash
pip install -r requirements.txt
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Cháº¡y Classification Model
```bash
python classification.py
```

Output:
- Model Ä‘Æ°á»£c lÆ°u táº¡i: `finalized_model.pkl`
- Hiá»ƒn thá»‹ accuracy, precision, recall, F1-score
- Confusion matrix

### Cháº¡y Regression Model
```bash
python regression.py
```

Output:
- Model Ä‘Æ°á»£c lÆ°u táº¡i: `student_score_model.pkl`
- Hiá»ƒn thá»‹ MAE, MSE, RÂ² score
- Dá»± Ä‘oÃ¡n máº«u vá»›i 2 há»c sinh

### Cháº¡y Job Classifier Model
```bash
python job_classifier.py
```

Output:
- Hiá»ƒn thá»‹ phÃ¢n phá»‘i class trÆ°á»›c vÃ  sau over-sampling
- Classification report vá»›i precision, recall, F1-score cho tá»«ng class
- Overall accuracy: ~76%

### Cháº¡y Time Series - Direct Multi-step
```bash
python direct_ts.py
```

Output:
- Metrics (MAE, MSE, RÂ²) cho 3 models (dá»± Ä‘oÃ¡n tuáº§n 1, 2, 3)
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c bÆ°á»›c dá»± Ä‘oÃ¡n

### Cháº¡y Time Series - Recursive Forecasting
```bash
python recursive_ts.py
```

Output:
- Dá»± Ä‘oÃ¡n 10 tuáº§n tiáº¿p theo tá»« dá»¯ liá»‡u ban Ä‘áº§u
- Hiá»ƒn thá»‹ MAE, MSE, RÂ² score
- Visualization: Ä‘á»“ thá»‹ so sÃ¡nh train/test/prediction
- Minh há»a quÃ¡ trÃ¬nh recursive prediction

### Load model Ä‘Ã£ lÆ°u
```python
import pickle

# Load classification model
with open('finalized_model.pkl', 'rb') as f:
    clf_model = pickle.load(f)

# Load regression model
with open('student_score_model.pkl', 'rb') as f:
    reg_model = pickle.load(f)
```

## ğŸ“ˆ Káº¿t quáº£

### Classification Model
- **Best Cross-validation Recall**: ~0.75
- **Test Accuracy**: ~0.77
- **Optimization**: GridSearchCV vá»›i 5-fold cross-validation
- **Metric tá»‘i Æ°u**: Recall (Ä‘á»ƒ phÃ¡t hiá»‡n nhiá»u ca bá»‡nh nháº¥t cÃ³ thá»ƒ)

### Regression Model
- **MAE**: ~4.0 Ä‘iá»ƒm
- **MSE**: ~25.0
- **RÂ² Score**: ~0.88
- **Optimization**: GridSearchCV vá»›i 5-fold cross-validation

### Job Classifier Model
- **Overall Accuracy**: ~76%
- **Best performing class**: senior_specialist_or_project_manager (F1=0.87)
- **Challenges**: Imbalanced data vá»›i má»™t sá»‘ class ráº¥t Ã­t samples
- **Techniques used**:
  - Random Over-sampling Ä‘á»ƒ cÃ¢n báº±ng training data
  - TF-IDF vá»›i unigrams + bigrams cho text processing
  - Chi-square feature selection (top 5% features)
  - Random Forest vá»›i 100 trees

**Performance by class:**
- senior_specialist_or_project_manager: F1=0.87 âœ…
- manager_team_leader: F1=0.69 âœ…
- bereichsleiter: F1=0.19 âš ï¸
- director_business_unit_leader: F1=0.25 âš ï¸
- specialist: F1=0.00 âŒ

### Time Series - Direct Multi-step Model
Dá»± Ä‘oÃ¡n 3 tuáº§n cÃ¹ng lÃºc vá»›i 3 models riÃªng biá»‡t:
- **Model 1** (tuáº§n +1): MAE, MSE, RÂ² varies
- **Model 2** (tuáº§n +2): MAE, MSE, RÂ² varies
- **Model 3** (tuáº§n +3): MAE, MSE, RÂ² varies
- **Æ¯u Ä‘iá»ƒm**: Má»—i model Ä‘Æ°á»£c tá»‘i Æ°u cho bÆ°á»›c dá»± Ä‘oÃ¡n cá»¥ thá»ƒ
- **NhÆ°á»£c Ä‘iá»ƒm**: Cáº§n train nhiá»u models, khÃ´ng cÃ³ dependency giá»¯a cÃ¡c predictions

### Time Series - Recursive Model
- **MAE**: 0.36
- **MSE**: 0.22
- **RÂ² Score**: 0.99 âœ¨
- **Æ¯u Ä‘iá»ƒm**: 
  - Chá»‰ cáº§n 1 model
  - CÃ³ thá»ƒ dá»± Ä‘oÃ¡n vÃ´ háº¡n bÆ°á»›c vá» tÆ°Æ¡ng lai
  - RÂ² score ráº¥t cao (~99%)
- **NhÆ°á»£c Ä‘iá»ƒm**: 
  - Lá»—i tÃ­ch lÅ©y qua cÃ¡c bÆ°á»›c
  - Uncertainty tÄƒng theo thá»i gian dá»± Ä‘oÃ¡n

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
ml-projects/
â”‚
â”œâ”€â”€ classification.py           # Code phÃ¢n loáº¡i bá»‡nh tiá»ƒu Ä‘Æ°á»ng
â”œâ”€â”€ regression.py              # Code dá»± Ä‘oÃ¡n Ä‘iá»ƒm sá»‘
â”œâ”€â”€ job_classifier.py          # Code phÃ¢n loáº¡i cáº¥p Ä‘á»™ nghá» nghiá»‡p
â”œâ”€â”€ direct_ts.py               # Code time series - direct multi-step
â”œâ”€â”€ recursive_ts.py            # Code time series - recursive forecasting
â”œâ”€â”€ requirements.txt           # ThÆ° viá»‡n cáº§n thiáº¿t
â”œâ”€â”€ README.md                  # File nÃ y
â”‚
â”œâ”€â”€ finalized_model.pkl        # Model classification Ä‘Ã£ train
â”œâ”€â”€ student_score_model.pkl    # Model regression Ä‘Ã£ train
```

## ğŸ” Chi tiáº¿t ká»¹ thuáº­t

### Classification Pipeline
1. Load data
2. Train/Test split (80/20)
3. StandardScaler normalization
4. GridSearchCV vá»›i Random Forest
5. Evaluation vá»›i nhiá»u metrics
6. LÆ°u model

### Regression Pipeline
1. Load data
2. Train/Test split (80/20)
3. Preprocessing Pipeline:
   - Numeric features: Imputation + Scaling
   - Ordinal features: Imputation + Ordinal Encoding
   - Nominal features: Imputation + One-Hot Encoding
4. GridSearchCV vá»›i Random Forest
5. Evaluation (MAE, MSE, RÂ²)
6. Test vá»›i dá»¯ liá»‡u máº«u
7. LÆ°u model

### Job Classifier Pipeline
1. Load data vÃ  xá»­ lÃ½ missing values
2. Location preprocessing (extract state code)
3. Train/Test split (80/20, stratified)
4. Random Over-sampling (cÃ¢n báº±ng classes trong training set)
5. Feature Engineering:
   - TF-IDF vectorization cho title
   - TF-IDF vá»›i unigrams+bigrams cho description (min_df=0.01, max_df=0.99)
   - One-Hot Encoding cho location, function, industry
6. Feature Selection: SelectPercentile (chi-square, top 5%)
7. Random Forest Classification
8. Evaluation vá»›i classification report

### Time Series Pipeline

#### Direct Multi-step Approach:
1. Load vÃ  preprocess data (interpolate missing values)
2. Create sliding windows:
   - Input: 5 tuáº§n liÃªn tiáº¿p (window_size=5)
   - Output: 3 tuáº§n tiáº¿p theo (target_size=3)
3. Train/Test split theo thá»i gian (80/20)
4. Train 3 models riÃªng biá»‡t:
   - Model 1: predict t+1
   - Model 2: predict t+2
   - Model 3: predict t+3
5. Evaluate tá»«ng model Ä‘á»™c láº­p

#### Recursive Approach:
1. Load vÃ  preprocess data (interpolate missing values)
2. Create sliding windows:
   - Input: 5 tuáº§n liÃªn tiáº¿p (window_size=5)
   - Output: 1 tuáº§n tiáº¿p theo
3. Train/Test split theo thá»i gian (80/20)
4. Train 1 model duy nháº¥t
5. Recursive prediction:
   - Dá»± Ä‘oÃ¡n tuáº§n tiáº¿p theo
   - ThÃªm prediction vÃ o input window
   - Loáº¡i bá» giÃ¡ trá»‹ cÅ© nháº¥t
   - Láº·p láº¡i cho cÃ¡c tuáº§n sau
6. Visualization káº¿t quáº£

## ğŸ“Š So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p Time Series

| TiÃªu chÃ­ | Direct Multi-step | Recursive |
|----------|------------------|-----------|
| **Sá»‘ models** | 3 models | 1 model |
| **Complexity** | Cao hÆ¡n | ÄÆ¡n giáº£n hÆ¡n |
| **Training time** | LÃ¢u hÆ¡n | Nhanh hÆ¡n |
| **Error accumulation** | KhÃ´ng cÃ³ | CÃ³ (tÄƒng theo thá»i gian) |
| **Flexibility** | Giá»›i háº¡n (3 bÆ°á»›c) | VÃ´ háº¡n bÆ°á»›c |
| **Best for** | Short-term forecast | Long-term forecast |
| **RÂ² Score** | Varies | 0.99 |

## ğŸ“ License

MIT License

## ğŸ‘¤ Author

lequangduyet03 - [GitHub](https://github.com/lequangduyet03)

## ğŸ¤ Contributing

Contributions, issues vÃ  feature requests Ä‘á»u Ä‘Æ°á»£c chÃ o Ä‘Ã³n!

## ğŸš§ Future Improvements

### Job Classifier
- Thu tháº­p thÃªm data cho rare classes
- Thá»­ nghiá»‡m vá»›i XGBoost, Neural Networks
- Feature engineering nÃ¢ng cao (years of experience, salary range)
- Hyperparameter tuning cho Random Forest
- Ensemble methods

### Time Series Models
- Thá»­ nghiá»‡m vá»›i ARIMA, SARIMA
- Implement LSTM/GRU cho sequential data
- ThÃªm seasonal decomposition
- Hybrid models (ARIMA + ML)
- Add confidence intervals cho predictions
- Feature engineering: lag features, rolling statistics, trend components
- Thá»­ nghiá»‡m vá»›i Random Forest Regressor thay vÃ¬ Linear Regression

---

â­ Náº¿u project nÃ y há»¯u Ã­ch, hÃ£y cho 1 star nhÃ©!